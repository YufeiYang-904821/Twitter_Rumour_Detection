{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bc5904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/305 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start crawling train tweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [21:29<00:00,  4.23s/it]   \n",
      "  0%|          | 0/106 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish crawling train tweet\n",
      "Start crawling dev tweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [01:07<00:00,  1.57it/s]\n",
      "  0%|          | 0/2547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish crawling dev tweet\n",
      "Start crawling covid tweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2547/2547 [3:02:25<00:00,  4.30s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish crawling covid tweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAHLrbgEAAAAA777OwnP8h1tYMwnBUv9JW84UIuU%3DAmrUujZvDvPBHsf8yN0tsEx0D4OBK0Cj50hnAapZo44PMuimGa\"\n",
    "\n",
    "\n",
    "def create_url(ids):\n",
    "    tweet_fields = \"tweet.fields=attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,possibly_sensitive,public_metrics,referenced_tweets,source,text,withheld\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    ids = \"ids=\" + ids\n",
    "    # You can adjust ids to include a single Tweets.\n",
    "    # Or you can add to up to 100 comma-separated IDs\n",
    "    url = \"https://api.twitter.com/2/tweets?{}&{}\".format(ids, tweet_fields)\n",
    "    return url\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
    "    #print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "def crawl_save(tweet_ids, output_folder):\n",
    "    tweet_id_list = []\n",
    "    for tweet_id in tweet_ids.readlines():\n",
    "        tweet_id_list.extend(tweet_id.strip().split(\",\"))\n",
    "    tweet_amount = len(tweet_id_list)\n",
    "    start_id = 0\n",
    "    end_id = 100\n",
    "    single_response_tweet_id = []\n",
    "    while start_id < tweet_amount:\n",
    "        single_response_tweet_id.append(\",\".join(tweet_id_list[start_id:end_id]))\n",
    "        start_id = end_id\n",
    "        end_id = start_id + 100\n",
    "\n",
    "    crawl_count = 0\n",
    "    for ids in tqdm(single_response_tweet_id):\n",
    "        url = create_url(ids)\n",
    "        json_responses = connect_to_endpoint(url)\n",
    "        for response in json_responses[\"data\"]:\n",
    "            json.dump(response, open(output_folder + str(response[\"id\"]) + \".json\", \"w\"))\n",
    "        crawl_count += 1\n",
    "        if crawl_count % 290 == 0:\n",
    "            time.sleep(1100)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "def main():\n",
    "#     url = create_url()\n",
    "#     json_response = connect_to_endpoint(url)\n",
    "#     print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    print(\"Start crawling train tweet\")\n",
    "    crawl_save(open(\"data/train.data.txt\", \"r\"), \"data/train_tweets/\")\n",
    "    print(\"Finish crawling train tweet\")\n",
    "    \n",
    "    print(\"Start crawling dev tweet\")\n",
    "    crawl_save(open(\"data/dev.data.txt\", \"r\"), \"data/dev_tweets/\")\n",
    "    print(\"Finish crawling dev tweet\")\n",
    "    \n",
    "    print(\"Start crawling covid tweet\")\n",
    "    crawl_save(open(\"data/covid.data.txt\", \"r\"), \"data/covid_tweets/\")\n",
    "    print(\"Finish crawling covid tweet\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854ce58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6199,
     "status": "ok",
     "timestamp": 1651929684441,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "vl2gDpXRQPrV",
    "outputId": "46e8c76e-ece9-41af-9c14-b24a6589f85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3536,
     "status": "ok",
     "timestamp": 1651929687971,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "VqNTVgpVQhXo"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "from pandas.core.frame import DataFrame\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1651929687972,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "-Lh_HCUjQYwn"
   },
   "outputs": [],
   "source": [
    "def getData(data_path, label_path, data_obejct_path):\n",
    "  data_texts = []\n",
    "  data_num_labels = []\n",
    "  data_ids = open(data_path, 'r')\n",
    "  data_labels = open(label_path, 'r')\n",
    "  for line in data_ids.readlines():\n",
    "    temp = []\n",
    "    temp_data = line.strip('\\n')\n",
    "    ids = temp_data.split(',')\n",
    "    for id in ids:\n",
    "      f = open(data_obejct_path + str(id) + '.json', 'r')\n",
    "      data = json.load(f)\n",
    "      temp.append(data['text'])\n",
    "    data_texts.append(' '.join(temp))\n",
    "\n",
    "  for line in data_labels.readlines():\n",
    "    label = line.strip('\\n')\n",
    "    if label == \"rumour\":\n",
    "        data_num_labels.append('1')\n",
    "    elif label == \"nonrumour\":\n",
    "        data_num_labels.append('0')\n",
    "  \n",
    "  return DataFrame({\"text\":data_texts, \"label\":data_num_labels})\n",
    "\n",
    "\n",
    "def getDataForTest(data_path, data_obejct_path):\n",
    "  data_texts = []\n",
    "  data_ids = open(data_path, 'r')\n",
    "  for line in data_ids.readlines():\n",
    "    temp = []\n",
    "    temp_data = line.strip('\\n')\n",
    "    ids = temp_data.split(',')\n",
    "    for id in ids:\n",
    "      f = open(data_obejct_path + str(id) + '.json', 'r')\n",
    "      data = json.load(f)\n",
    "      temp.append(data['text'])\n",
    "    data_texts.append(' '.join(temp))\n",
    "  \n",
    "  return DataFrame({\"text\":data_texts})\n",
    "\n",
    "\n",
    "def covert_to_label(probs):\n",
    "  res = []\n",
    "  for i in probs:\n",
    "    if i[0] > 0.5 :\n",
    "      res.append(1)\n",
    "    else:\n",
    "      res.append(0)\n",
    "  return res\n",
    "\n",
    "\n",
    "def cleanData(data):\n",
    "    data['text'] = data['text'].apply(lambda x: re.sub(r'[0-9]+\\.', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1651929687973,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "m3LLJ74gQZpl",
    "outputId": "a332da8e-8648-40b7-aa2e-e4b5a6dce782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Can regularly rinsing your nose with saline help prevent infection with the new coronavirus? https://t.co/ccMjhhD7BK   Can eating garlic help prevent infection with the new coronavirus? #COVID19Malaysia https://t.co/q133xXBiwl   Do vaccines against pneumonia protect you against the new coronavirus? https://t.co/wL0mlEqU95   Can spraying alcohol or chlorine all over your body kill the new coronavirus? #Chamber https://t.co/zunVR7Ht0V   How effective are thermal scanners in detecting people infected with the new coronavirus? https://t.co/nyLOyKAb1H   Can an ultraviolet disinfection lamp kill the new coronavirus? https://t.co/ZrlllbkIjm   Are hand dryers effective in killing the new coronavirus? https://t.co/cSDKXO1bGr   The new coronavirus CANNOT be transmitted through mosquito bites. https://t.co/ZRL8bjRkpl   Taking a hot bath does not prevent the new coronavirus disease https://t.co/bICOqSTOuD   Cold weather and snow CANNOT kill the new coronavirus. https://t.co/7yeQQ6gLNo   COVID-19 virus can be transmitted in areas with hot and humid climates https://t.co/ylKa2F40vu   Drinking alcohol does not protect you against COVID-19 and can be dangerous https://t.co/ZrLN61q046   Being able to hold your breath for 10 seconds or more without coughing or feeling discomfort DOES NOT mean you… https://t.co/jh4G9lDDoK   You can recover from the coronavirus disease (COVID-19). Catching the new coronavirus DOES NOT mean you will ha… https://t.co/Jv5GEJM4io   Exposing yourself to the sun or to temperatures higher than 25C degrees DOES NOT prevent the coronavirus diseas… https://t.co/ePM21cohrJ   5G mobile networks DO NOT spread COVID-19 https://t.co/VjqelBmpTn\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('/content/drive/MyDrive/nlp/train.csv')\n",
    "dev_data = pd.read_csv('/content/drive/MyDrive/nlp/dev.csv')\n",
    "test_data = pd.read_csv('/content/drive/MyDrive/nlp/test.csv')\n",
    "\n",
    "cleanData(train_data)\n",
    "cleanData(dev_data)\n",
    "cleanData(test_data)\n",
    "\n",
    "print(train_data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1651929687973,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "0uq075LMXyzG"
   },
   "outputs": [],
   "source": [
    "def get_bert_tokens(data):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\", normalization=True)\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "  for tweet in data['text'].values:\n",
    "    encoding = tokenizer.encode_plus(\n",
    "               tweet,\n",
    "               max_length = 128,                    \n",
    "               add_special_tokens = True,\n",
    "               padding = 'max_length', \n",
    "               return_attention_mask = True,  \n",
    "               truncation = True,\n",
    "               return_tensors = 'pt',\n",
    "               )\n",
    "    input_ids.append(encoding['input_ids'])\n",
    "    attention_masks.append(encoding['attention_mask'])\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "  data_map = {'input_ids': input_ids, 'attention_masks':attention_masks}\n",
    "  return data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11764,
     "status": "ok",
     "timestamp": 1651929699728,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "7qVvGfogdjen"
   },
   "outputs": [],
   "source": [
    "train_map = get_bert_tokens(train_data)\n",
    "dev_map = get_bert_tokens(dev_data)\n",
    "test_map = get_bert_tokens(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1651929699729,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "4EZ1hcCJe5Jt"
   },
   "outputs": [],
   "source": [
    "def create_data_loader_for_train(data ,data_map, batch_size):\n",
    "  labels = torch.tensor(data['label'])\n",
    "  dataset = TensorDataset(data_map['input_ids'], data_map['attention_masks'], labels)\n",
    "  dataloader = DataLoader(\n",
    "               dataset,\n",
    "               sampler = RandomSampler(dataset), \n",
    "               batch_size = batch_size\n",
    "               )\n",
    "  return dataloader\n",
    "\n",
    "\n",
    "def create_data_loader_for_dev(data ,data_map, batch_size):\n",
    "  labels = torch.tensor(data['label'])\n",
    "  dataset = TensorDataset(data_map['input_ids'], data_map['attention_masks'], labels)\n",
    "  dataloader = DataLoader(\n",
    "               dataset,\n",
    "               sampler = SequentialSampler(dataset), \n",
    "               batch_size = batch_size\n",
    "               )\n",
    "  return dataloader\n",
    "\n",
    "\n",
    "def create_data_loader_for_test(data_map, batch_size):\n",
    "  dataset = TensorDataset(data_map['input_ids'], data_map['attention_masks'])\n",
    "  dataloader = DataLoader(\n",
    "               dataset, \n",
    "               sampler = SequentialSampler(dataset), \n",
    "               batch_size = batch_size\n",
    "               )\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1651929699730,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "D2rlMbLohxW9"
   },
   "outputs": [],
   "source": [
    "train_dataloader = create_data_loader_for_train(train_data, train_map, 16)\n",
    "dev_dataloader = create_data_loader_for_dev(dev_data, dev_map, 16)\n",
    "test_dataloader = create_data_loader_for_test(test_map, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1651929699730,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "gTV9lDky1Gg9"
   },
   "outputs": [],
   "source": [
    "class RunmorClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.bert = AutoModel.from_pretrained(\"vinai/bertweet-large\")\n",
    "    self.drop_layer = nn.Dropout(p=0.5) \n",
    "    self.cls_layer = nn.Linear(self.bert.config.hidden_size, 1)  \n",
    "     \n",
    "  def forward(self, seq, attention_mask):\n",
    "    output = self.bert(seq, attention_mask = attention_mask)\n",
    "    output = self.drop_layer(output['pooler_output'])\n",
    "    logits = self.cls_layer(output)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1651929699731,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "h6GCYBjc2sX9"
   },
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1651929699731,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "1IS0p3wP_JXc"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, dev_dataloader, gpu):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "    \n",
    "    label_list = []\n",
    "    res = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_masks, labels in dev_dataloader:\n",
    "            cuda_input_ids = input_ids.cuda(gpu)\n",
    "            cuda_attention_masks = attention_masks.cuda(gpu)\n",
    "            cuda_labels = labels.cuda(gpu)\n",
    "\n",
    "            logits = model(cuda_input_ids, cuda_attention_masks)\n",
    "\n",
    "            mean_loss += criterion(logits.squeeze(-1), cuda_labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, cuda_labels)\n",
    "            count += 1\n",
    "\n",
    "            probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "            probs = probs.detach().cpu().numpy()\n",
    "            label_temp = labels.detach().cpu().numpy()\n",
    "            for prob in probs:\n",
    "              res.append(prob)\n",
    "            for label in label_temp:\n",
    "              label_list.append(label)\n",
    "\n",
    "    predictions = covert_to_label(res)\n",
    "    f1 = f1_score(label_list, predictions)\n",
    "    precision = precision_score(label_list, predictions)\n",
    "    recall = recall_score(label_list, predictions)\n",
    "\n",
    "    return mean_acc / count, mean_loss / count, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1651929699732,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "tpkCw1TlNNgX"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, gpu):\n",
    "  model.eval()\n",
    "  res = []\n",
    "  with torch.no_grad():\n",
    "    for input_ids, attention_masks, _ in dataloader:\n",
    "      cuda_input_ids = input_ids.cuda(gpu)\n",
    "      cuda_attention_masks = attention_masks.cuda(gpu)\n",
    "      logits = model(cuda_input_ids, cuda_attention_masks)\n",
    "      probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "      probs = probs.detach().cpu().numpy()\n",
    "      for prob in probs:\n",
    "        res.append(prob)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1651929699732,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "Nr7vQ4jA_Jxn"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, dev_dataloader, epochs, gpu, ):\n",
    "\n",
    "    for i in range(0, epochs):        \n",
    "        model.train()\n",
    "        print(\"Epoch \" + str(i+1))\n",
    "        total_train_loss = 0\n",
    "        for it, (input_ids, attention_masks, labels) in enumerate(train_dataloader):\n",
    "            model.zero_grad() \n",
    "            cuda_input_ids = input_ids.cuda(gpu)\n",
    "            cuda_attention_masks = attention_masks.cuda(gpu)\n",
    "            cuda_labels = labels.cuda(gpu)\n",
    "            \n",
    "            logits = model(cuda_input_ids, cuda_attention_masks)\n",
    "            loss = criterion(logits.squeeze(-1), cuda_labels.float())\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(\"Batch {} of epoch {} complete.\".format(it, i+1))\n",
    "        \n",
    "        print(\"Train loss: {0:.2f}\".format(total_train_loss/len(train_dataloader)))    \n",
    "        dev_acc, dev_loss, dev_f1, dev_precision, dev_recall = evaluate(model, criterion, dev_dataloader, gpu)\n",
    "        print(\"Dev loss: {0:.2f}\".format(dev_loss))\n",
    "        print(\"Dev acc: {0:.2f}\".format(dev_acc))\n",
    "        print(\"Dev f1: {0:.2f}\".format(dev_f1))\n",
    "        print(\"Dev precision: {0:.2f}\".format(dev_precision))\n",
    "        print(\"Dev recall: {0:.2f}\".format(dev_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8823,
     "status": "ok",
     "timestamp": 1651929708533,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "8qyFlly3cWfZ",
    "outputId": "5a44d544-c58f-472c-ccdb-8fdd1272f8ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "model = RunmorClassifier()\n",
    "model.cuda(gpu)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 2e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "epochs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523616,
     "status": "ok",
     "timestamp": 1651930232131,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "HDZiIUBb_WD0",
    "outputId": "6e3f15be-ef63-4864-85ed-e2b75a7a6146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch 0 of epoch 1 complete.\n",
      "Batch 1 of epoch 1 complete.\n",
      "Batch 2 of epoch 1 complete.\n",
      "Batch 3 of epoch 1 complete.\n",
      "Batch 4 of epoch 1 complete.\n",
      "Batch 5 of epoch 1 complete.\n",
      "Batch 6 of epoch 1 complete.\n",
      "Batch 7 of epoch 1 complete.\n",
      "Batch 8 of epoch 1 complete.\n",
      "Batch 9 of epoch 1 complete.\n",
      "Batch 10 of epoch 1 complete.\n",
      "Batch 11 of epoch 1 complete.\n",
      "Batch 12 of epoch 1 complete.\n",
      "Batch 13 of epoch 1 complete.\n",
      "Batch 14 of epoch 1 complete.\n",
      "Batch 15 of epoch 1 complete.\n",
      "Batch 16 of epoch 1 complete.\n",
      "Batch 17 of epoch 1 complete.\n",
      "Batch 18 of epoch 1 complete.\n",
      "Batch 19 of epoch 1 complete.\n",
      "Batch 20 of epoch 1 complete.\n",
      "Batch 21 of epoch 1 complete.\n",
      "Batch 22 of epoch 1 complete.\n",
      "Batch 23 of epoch 1 complete.\n",
      "Batch 24 of epoch 1 complete.\n",
      "Batch 25 of epoch 1 complete.\n",
      "Batch 26 of epoch 1 complete.\n",
      "Batch 27 of epoch 1 complete.\n",
      "Batch 28 of epoch 1 complete.\n",
      "Batch 29 of epoch 1 complete.\n",
      "Batch 30 of epoch 1 complete.\n",
      "Batch 31 of epoch 1 complete.\n",
      "Batch 32 of epoch 1 complete.\n",
      "Batch 33 of epoch 1 complete.\n",
      "Batch 34 of epoch 1 complete.\n",
      "Batch 35 of epoch 1 complete.\n",
      "Batch 36 of epoch 1 complete.\n",
      "Batch 37 of epoch 1 complete.\n",
      "Batch 38 of epoch 1 complete.\n",
      "Batch 39 of epoch 1 complete.\n",
      "Batch 40 of epoch 1 complete.\n",
      "Batch 41 of epoch 1 complete.\n",
      "Batch 42 of epoch 1 complete.\n",
      "Batch 43 of epoch 1 complete.\n",
      "Batch 44 of epoch 1 complete.\n",
      "Batch 45 of epoch 1 complete.\n",
      "Batch 46 of epoch 1 complete.\n",
      "Batch 47 of epoch 1 complete.\n",
      "Batch 48 of epoch 1 complete.\n",
      "Batch 49 of epoch 1 complete.\n",
      "Batch 50 of epoch 1 complete.\n",
      "Batch 51 of epoch 1 complete.\n",
      "Batch 52 of epoch 1 complete.\n",
      "Batch 53 of epoch 1 complete.\n",
      "Batch 54 of epoch 1 complete.\n",
      "Batch 55 of epoch 1 complete.\n",
      "Batch 56 of epoch 1 complete.\n",
      "Batch 57 of epoch 1 complete.\n",
      "Batch 58 of epoch 1 complete.\n",
      "Batch 59 of epoch 1 complete.\n",
      "Batch 60 of epoch 1 complete.\n",
      "Batch 61 of epoch 1 complete.\n",
      "Batch 62 of epoch 1 complete.\n",
      "Batch 63 of epoch 1 complete.\n",
      "Batch 64 of epoch 1 complete.\n",
      "Batch 65 of epoch 1 complete.\n",
      "Batch 66 of epoch 1 complete.\n",
      "Batch 67 of epoch 1 complete.\n",
      "Batch 68 of epoch 1 complete.\n",
      "Batch 69 of epoch 1 complete.\n",
      "Batch 70 of epoch 1 complete.\n",
      "Batch 71 of epoch 1 complete.\n",
      "Batch 72 of epoch 1 complete.\n",
      "Batch 73 of epoch 1 complete.\n",
      "Batch 74 of epoch 1 complete.\n",
      "Batch 75 of epoch 1 complete.\n",
      "Batch 76 of epoch 1 complete.\n",
      "Batch 77 of epoch 1 complete.\n",
      "Batch 78 of epoch 1 complete.\n",
      "Batch 79 of epoch 1 complete.\n",
      "Batch 80 of epoch 1 complete.\n",
      "Batch 81 of epoch 1 complete.\n",
      "Batch 82 of epoch 1 complete.\n",
      "Batch 83 of epoch 1 complete.\n",
      "Batch 84 of epoch 1 complete.\n",
      "Batch 85 of epoch 1 complete.\n",
      "Batch 86 of epoch 1 complete.\n",
      "Batch 87 of epoch 1 complete.\n",
      "Batch 88 of epoch 1 complete.\n",
      "Batch 89 of epoch 1 complete.\n",
      "Batch 90 of epoch 1 complete.\n",
      "Batch 91 of epoch 1 complete.\n",
      "Batch 92 of epoch 1 complete.\n",
      "Batch 93 of epoch 1 complete.\n",
      "Batch 94 of epoch 1 complete.\n",
      "Batch 95 of epoch 1 complete.\n",
      "Batch 96 of epoch 1 complete.\n",
      "Train loss: 0.46\n",
      "Dev loss: 0.38\n",
      "Dev acc: 0.83\n",
      "Dev f1: 0.67\n",
      "Dev precision: 0.58\n",
      "Dev recall: 0.78\n",
      "Epoch 2\n",
      "Batch 0 of epoch 2 complete.\n",
      "Batch 1 of epoch 2 complete.\n",
      "Batch 2 of epoch 2 complete.\n",
      "Batch 3 of epoch 2 complete.\n",
      "Batch 4 of epoch 2 complete.\n",
      "Batch 5 of epoch 2 complete.\n",
      "Batch 6 of epoch 2 complete.\n",
      "Batch 7 of epoch 2 complete.\n",
      "Batch 8 of epoch 2 complete.\n",
      "Batch 9 of epoch 2 complete.\n",
      "Batch 10 of epoch 2 complete.\n",
      "Batch 11 of epoch 2 complete.\n",
      "Batch 12 of epoch 2 complete.\n",
      "Batch 13 of epoch 2 complete.\n",
      "Batch 14 of epoch 2 complete.\n",
      "Batch 15 of epoch 2 complete.\n",
      "Batch 16 of epoch 2 complete.\n",
      "Batch 17 of epoch 2 complete.\n",
      "Batch 18 of epoch 2 complete.\n",
      "Batch 19 of epoch 2 complete.\n",
      "Batch 20 of epoch 2 complete.\n",
      "Batch 21 of epoch 2 complete.\n",
      "Batch 22 of epoch 2 complete.\n",
      "Batch 23 of epoch 2 complete.\n",
      "Batch 24 of epoch 2 complete.\n",
      "Batch 25 of epoch 2 complete.\n",
      "Batch 26 of epoch 2 complete.\n",
      "Batch 27 of epoch 2 complete.\n",
      "Batch 28 of epoch 2 complete.\n",
      "Batch 29 of epoch 2 complete.\n",
      "Batch 30 of epoch 2 complete.\n",
      "Batch 31 of epoch 2 complete.\n",
      "Batch 32 of epoch 2 complete.\n",
      "Batch 33 of epoch 2 complete.\n",
      "Batch 34 of epoch 2 complete.\n",
      "Batch 35 of epoch 2 complete.\n",
      "Batch 36 of epoch 2 complete.\n",
      "Batch 37 of epoch 2 complete.\n",
      "Batch 38 of epoch 2 complete.\n",
      "Batch 39 of epoch 2 complete.\n",
      "Batch 40 of epoch 2 complete.\n",
      "Batch 41 of epoch 2 complete.\n",
      "Batch 42 of epoch 2 complete.\n",
      "Batch 43 of epoch 2 complete.\n",
      "Batch 44 of epoch 2 complete.\n",
      "Batch 45 of epoch 2 complete.\n",
      "Batch 46 of epoch 2 complete.\n",
      "Batch 47 of epoch 2 complete.\n",
      "Batch 48 of epoch 2 complete.\n",
      "Batch 49 of epoch 2 complete.\n",
      "Batch 50 of epoch 2 complete.\n",
      "Batch 51 of epoch 2 complete.\n",
      "Batch 52 of epoch 2 complete.\n",
      "Batch 53 of epoch 2 complete.\n",
      "Batch 54 of epoch 2 complete.\n",
      "Batch 55 of epoch 2 complete.\n",
      "Batch 56 of epoch 2 complete.\n",
      "Batch 57 of epoch 2 complete.\n",
      "Batch 58 of epoch 2 complete.\n",
      "Batch 59 of epoch 2 complete.\n",
      "Batch 60 of epoch 2 complete.\n",
      "Batch 61 of epoch 2 complete.\n",
      "Batch 62 of epoch 2 complete.\n",
      "Batch 63 of epoch 2 complete.\n",
      "Batch 64 of epoch 2 complete.\n",
      "Batch 65 of epoch 2 complete.\n",
      "Batch 66 of epoch 2 complete.\n",
      "Batch 67 of epoch 2 complete.\n",
      "Batch 68 of epoch 2 complete.\n",
      "Batch 69 of epoch 2 complete.\n",
      "Batch 70 of epoch 2 complete.\n",
      "Batch 71 of epoch 2 complete.\n",
      "Batch 72 of epoch 2 complete.\n",
      "Batch 73 of epoch 2 complete.\n",
      "Batch 74 of epoch 2 complete.\n",
      "Batch 75 of epoch 2 complete.\n",
      "Batch 76 of epoch 2 complete.\n",
      "Batch 77 of epoch 2 complete.\n",
      "Batch 78 of epoch 2 complete.\n",
      "Batch 79 of epoch 2 complete.\n",
      "Batch 80 of epoch 2 complete.\n",
      "Batch 81 of epoch 2 complete.\n",
      "Batch 82 of epoch 2 complete.\n",
      "Batch 83 of epoch 2 complete.\n",
      "Batch 84 of epoch 2 complete.\n",
      "Batch 85 of epoch 2 complete.\n",
      "Batch 86 of epoch 2 complete.\n",
      "Batch 87 of epoch 2 complete.\n",
      "Batch 88 of epoch 2 complete.\n",
      "Batch 89 of epoch 2 complete.\n",
      "Batch 90 of epoch 2 complete.\n",
      "Batch 91 of epoch 2 complete.\n",
      "Batch 92 of epoch 2 complete.\n",
      "Batch 93 of epoch 2 complete.\n",
      "Batch 94 of epoch 2 complete.\n",
      "Batch 95 of epoch 2 complete.\n",
      "Batch 96 of epoch 2 complete.\n",
      "Train loss: 0.28\n",
      "Dev loss: 0.19\n",
      "Dev acc: 0.93\n",
      "Dev f1: 0.82\n",
      "Dev precision: 0.90\n",
      "Dev recall: 0.76\n",
      "Epoch 3\n",
      "Batch 0 of epoch 3 complete.\n",
      "Batch 1 of epoch 3 complete.\n",
      "Batch 2 of epoch 3 complete.\n",
      "Batch 3 of epoch 3 complete.\n",
      "Batch 4 of epoch 3 complete.\n",
      "Batch 5 of epoch 3 complete.\n",
      "Batch 6 of epoch 3 complete.\n",
      "Batch 7 of epoch 3 complete.\n",
      "Batch 8 of epoch 3 complete.\n",
      "Batch 9 of epoch 3 complete.\n",
      "Batch 10 of epoch 3 complete.\n",
      "Batch 11 of epoch 3 complete.\n",
      "Batch 12 of epoch 3 complete.\n",
      "Batch 13 of epoch 3 complete.\n",
      "Batch 14 of epoch 3 complete.\n",
      "Batch 15 of epoch 3 complete.\n",
      "Batch 16 of epoch 3 complete.\n",
      "Batch 17 of epoch 3 complete.\n",
      "Batch 18 of epoch 3 complete.\n",
      "Batch 19 of epoch 3 complete.\n",
      "Batch 20 of epoch 3 complete.\n",
      "Batch 21 of epoch 3 complete.\n",
      "Batch 22 of epoch 3 complete.\n",
      "Batch 23 of epoch 3 complete.\n",
      "Batch 24 of epoch 3 complete.\n",
      "Batch 25 of epoch 3 complete.\n",
      "Batch 26 of epoch 3 complete.\n",
      "Batch 27 of epoch 3 complete.\n",
      "Batch 28 of epoch 3 complete.\n",
      "Batch 29 of epoch 3 complete.\n",
      "Batch 30 of epoch 3 complete.\n",
      "Batch 31 of epoch 3 complete.\n",
      "Batch 32 of epoch 3 complete.\n",
      "Batch 33 of epoch 3 complete.\n",
      "Batch 34 of epoch 3 complete.\n",
      "Batch 35 of epoch 3 complete.\n",
      "Batch 36 of epoch 3 complete.\n",
      "Batch 37 of epoch 3 complete.\n",
      "Batch 38 of epoch 3 complete.\n",
      "Batch 39 of epoch 3 complete.\n",
      "Batch 40 of epoch 3 complete.\n",
      "Batch 41 of epoch 3 complete.\n",
      "Batch 42 of epoch 3 complete.\n",
      "Batch 43 of epoch 3 complete.\n",
      "Batch 44 of epoch 3 complete.\n",
      "Batch 45 of epoch 3 complete.\n",
      "Batch 46 of epoch 3 complete.\n",
      "Batch 47 of epoch 3 complete.\n",
      "Batch 48 of epoch 3 complete.\n",
      "Batch 49 of epoch 3 complete.\n",
      "Batch 50 of epoch 3 complete.\n",
      "Batch 51 of epoch 3 complete.\n",
      "Batch 52 of epoch 3 complete.\n",
      "Batch 53 of epoch 3 complete.\n",
      "Batch 54 of epoch 3 complete.\n",
      "Batch 55 of epoch 3 complete.\n",
      "Batch 56 of epoch 3 complete.\n",
      "Batch 57 of epoch 3 complete.\n",
      "Batch 58 of epoch 3 complete.\n",
      "Batch 59 of epoch 3 complete.\n",
      "Batch 60 of epoch 3 complete.\n",
      "Batch 61 of epoch 3 complete.\n",
      "Batch 62 of epoch 3 complete.\n",
      "Batch 63 of epoch 3 complete.\n",
      "Batch 64 of epoch 3 complete.\n",
      "Batch 65 of epoch 3 complete.\n",
      "Batch 66 of epoch 3 complete.\n",
      "Batch 67 of epoch 3 complete.\n",
      "Batch 68 of epoch 3 complete.\n",
      "Batch 69 of epoch 3 complete.\n",
      "Batch 70 of epoch 3 complete.\n",
      "Batch 71 of epoch 3 complete.\n",
      "Batch 72 of epoch 3 complete.\n",
      "Batch 73 of epoch 3 complete.\n",
      "Batch 74 of epoch 3 complete.\n",
      "Batch 75 of epoch 3 complete.\n",
      "Batch 76 of epoch 3 complete.\n",
      "Batch 77 of epoch 3 complete.\n",
      "Batch 78 of epoch 3 complete.\n",
      "Batch 79 of epoch 3 complete.\n",
      "Batch 80 of epoch 3 complete.\n",
      "Batch 81 of epoch 3 complete.\n",
      "Batch 82 of epoch 3 complete.\n",
      "Batch 83 of epoch 3 complete.\n",
      "Batch 84 of epoch 3 complete.\n",
      "Batch 85 of epoch 3 complete.\n",
      "Batch 86 of epoch 3 complete.\n",
      "Batch 87 of epoch 3 complete.\n",
      "Batch 88 of epoch 3 complete.\n",
      "Batch 89 of epoch 3 complete.\n",
      "Batch 90 of epoch 3 complete.\n",
      "Batch 91 of epoch 3 complete.\n",
      "Batch 92 of epoch 3 complete.\n",
      "Batch 93 of epoch 3 complete.\n",
      "Batch 94 of epoch 3 complete.\n",
      "Batch 95 of epoch 3 complete.\n",
      "Batch 96 of epoch 3 complete.\n",
      "Train loss: 0.13\n",
      "Dev loss: 0.15\n",
      "Dev acc: 0.96\n",
      "Dev f1: 0.90\n",
      "Dev precision: 0.93\n",
      "Dev recall: 0.87\n",
      "Epoch 4\n",
      "Batch 0 of epoch 4 complete.\n",
      "Batch 1 of epoch 4 complete.\n",
      "Batch 2 of epoch 4 complete.\n",
      "Batch 3 of epoch 4 complete.\n",
      "Batch 4 of epoch 4 complete.\n",
      "Batch 5 of epoch 4 complete.\n",
      "Batch 6 of epoch 4 complete.\n",
      "Batch 7 of epoch 4 complete.\n",
      "Batch 8 of epoch 4 complete.\n",
      "Batch 9 of epoch 4 complete.\n",
      "Batch 10 of epoch 4 complete.\n",
      "Batch 11 of epoch 4 complete.\n",
      "Batch 12 of epoch 4 complete.\n",
      "Batch 13 of epoch 4 complete.\n",
      "Batch 14 of epoch 4 complete.\n",
      "Batch 15 of epoch 4 complete.\n",
      "Batch 16 of epoch 4 complete.\n",
      "Batch 17 of epoch 4 complete.\n",
      "Batch 18 of epoch 4 complete.\n",
      "Batch 19 of epoch 4 complete.\n",
      "Batch 20 of epoch 4 complete.\n",
      "Batch 21 of epoch 4 complete.\n",
      "Batch 22 of epoch 4 complete.\n",
      "Batch 23 of epoch 4 complete.\n",
      "Batch 24 of epoch 4 complete.\n",
      "Batch 25 of epoch 4 complete.\n",
      "Batch 26 of epoch 4 complete.\n",
      "Batch 27 of epoch 4 complete.\n",
      "Batch 28 of epoch 4 complete.\n",
      "Batch 29 of epoch 4 complete.\n",
      "Batch 30 of epoch 4 complete.\n",
      "Batch 31 of epoch 4 complete.\n",
      "Batch 32 of epoch 4 complete.\n",
      "Batch 33 of epoch 4 complete.\n",
      "Batch 34 of epoch 4 complete.\n",
      "Batch 35 of epoch 4 complete.\n",
      "Batch 36 of epoch 4 complete.\n",
      "Batch 37 of epoch 4 complete.\n",
      "Batch 38 of epoch 4 complete.\n",
      "Batch 39 of epoch 4 complete.\n",
      "Batch 40 of epoch 4 complete.\n",
      "Batch 41 of epoch 4 complete.\n",
      "Batch 42 of epoch 4 complete.\n",
      "Batch 43 of epoch 4 complete.\n",
      "Batch 44 of epoch 4 complete.\n",
      "Batch 45 of epoch 4 complete.\n",
      "Batch 46 of epoch 4 complete.\n",
      "Batch 47 of epoch 4 complete.\n",
      "Batch 48 of epoch 4 complete.\n",
      "Batch 49 of epoch 4 complete.\n",
      "Batch 50 of epoch 4 complete.\n",
      "Batch 51 of epoch 4 complete.\n",
      "Batch 52 of epoch 4 complete.\n",
      "Batch 53 of epoch 4 complete.\n",
      "Batch 54 of epoch 4 complete.\n",
      "Batch 55 of epoch 4 complete.\n",
      "Batch 56 of epoch 4 complete.\n",
      "Batch 57 of epoch 4 complete.\n",
      "Batch 58 of epoch 4 complete.\n",
      "Batch 59 of epoch 4 complete.\n",
      "Batch 60 of epoch 4 complete.\n",
      "Batch 61 of epoch 4 complete.\n",
      "Batch 62 of epoch 4 complete.\n",
      "Batch 63 of epoch 4 complete.\n",
      "Batch 64 of epoch 4 complete.\n",
      "Batch 65 of epoch 4 complete.\n",
      "Batch 66 of epoch 4 complete.\n",
      "Batch 67 of epoch 4 complete.\n",
      "Batch 68 of epoch 4 complete.\n",
      "Batch 69 of epoch 4 complete.\n",
      "Batch 70 of epoch 4 complete.\n",
      "Batch 71 of epoch 4 complete.\n",
      "Batch 72 of epoch 4 complete.\n",
      "Batch 73 of epoch 4 complete.\n",
      "Batch 74 of epoch 4 complete.\n",
      "Batch 75 of epoch 4 complete.\n",
      "Batch 76 of epoch 4 complete.\n",
      "Batch 77 of epoch 4 complete.\n",
      "Batch 78 of epoch 4 complete.\n",
      "Batch 79 of epoch 4 complete.\n",
      "Batch 80 of epoch 4 complete.\n",
      "Batch 81 of epoch 4 complete.\n",
      "Batch 82 of epoch 4 complete.\n",
      "Batch 83 of epoch 4 complete.\n",
      "Batch 84 of epoch 4 complete.\n",
      "Batch 85 of epoch 4 complete.\n",
      "Batch 86 of epoch 4 complete.\n",
      "Batch 87 of epoch 4 complete.\n",
      "Batch 88 of epoch 4 complete.\n",
      "Batch 89 of epoch 4 complete.\n",
      "Batch 90 of epoch 4 complete.\n",
      "Batch 91 of epoch 4 complete.\n",
      "Batch 92 of epoch 4 complete.\n",
      "Batch 93 of epoch 4 complete.\n",
      "Batch 94 of epoch 4 complete.\n",
      "Batch 95 of epoch 4 complete.\n",
      "Batch 96 of epoch 4 complete.\n",
      "Train loss: 0.05\n",
      "Dev loss: 0.17\n",
      "Dev acc: 0.95\n",
      "Dev f1: 0.88\n",
      "Dev precision: 0.82\n",
      "Dev recall: 0.96\n",
      "Epoch 5\n",
      "Batch 0 of epoch 5 complete.\n",
      "Batch 1 of epoch 5 complete.\n",
      "Batch 2 of epoch 5 complete.\n",
      "Batch 3 of epoch 5 complete.\n",
      "Batch 4 of epoch 5 complete.\n",
      "Batch 5 of epoch 5 complete.\n",
      "Batch 6 of epoch 5 complete.\n",
      "Batch 7 of epoch 5 complete.\n",
      "Batch 8 of epoch 5 complete.\n",
      "Batch 9 of epoch 5 complete.\n",
      "Batch 10 of epoch 5 complete.\n",
      "Batch 11 of epoch 5 complete.\n",
      "Batch 12 of epoch 5 complete.\n",
      "Batch 13 of epoch 5 complete.\n",
      "Batch 14 of epoch 5 complete.\n",
      "Batch 15 of epoch 5 complete.\n",
      "Batch 16 of epoch 5 complete.\n",
      "Batch 17 of epoch 5 complete.\n",
      "Batch 18 of epoch 5 complete.\n",
      "Batch 19 of epoch 5 complete.\n",
      "Batch 20 of epoch 5 complete.\n",
      "Batch 21 of epoch 5 complete.\n",
      "Batch 22 of epoch 5 complete.\n",
      "Batch 23 of epoch 5 complete.\n",
      "Batch 24 of epoch 5 complete.\n",
      "Batch 25 of epoch 5 complete.\n",
      "Batch 26 of epoch 5 complete.\n",
      "Batch 27 of epoch 5 complete.\n",
      "Batch 28 of epoch 5 complete.\n",
      "Batch 29 of epoch 5 complete.\n",
      "Batch 30 of epoch 5 complete.\n",
      "Batch 31 of epoch 5 complete.\n",
      "Batch 32 of epoch 5 complete.\n",
      "Batch 33 of epoch 5 complete.\n",
      "Batch 34 of epoch 5 complete.\n",
      "Batch 35 of epoch 5 complete.\n",
      "Batch 36 of epoch 5 complete.\n",
      "Batch 37 of epoch 5 complete.\n",
      "Batch 38 of epoch 5 complete.\n",
      "Batch 39 of epoch 5 complete.\n",
      "Batch 40 of epoch 5 complete.\n",
      "Batch 41 of epoch 5 complete.\n",
      "Batch 42 of epoch 5 complete.\n",
      "Batch 43 of epoch 5 complete.\n",
      "Batch 44 of epoch 5 complete.\n",
      "Batch 45 of epoch 5 complete.\n",
      "Batch 46 of epoch 5 complete.\n",
      "Batch 47 of epoch 5 complete.\n",
      "Batch 48 of epoch 5 complete.\n",
      "Batch 49 of epoch 5 complete.\n",
      "Batch 50 of epoch 5 complete.\n",
      "Batch 51 of epoch 5 complete.\n",
      "Batch 52 of epoch 5 complete.\n",
      "Batch 53 of epoch 5 complete.\n",
      "Batch 54 of epoch 5 complete.\n",
      "Batch 55 of epoch 5 complete.\n",
      "Batch 56 of epoch 5 complete.\n",
      "Batch 57 of epoch 5 complete.\n",
      "Batch 58 of epoch 5 complete.\n",
      "Batch 59 of epoch 5 complete.\n",
      "Batch 60 of epoch 5 complete.\n",
      "Batch 61 of epoch 5 complete.\n",
      "Batch 62 of epoch 5 complete.\n",
      "Batch 63 of epoch 5 complete.\n",
      "Batch 64 of epoch 5 complete.\n",
      "Batch 65 of epoch 5 complete.\n",
      "Batch 66 of epoch 5 complete.\n",
      "Batch 67 of epoch 5 complete.\n",
      "Batch 68 of epoch 5 complete.\n",
      "Batch 69 of epoch 5 complete.\n",
      "Batch 70 of epoch 5 complete.\n",
      "Batch 71 of epoch 5 complete.\n",
      "Batch 72 of epoch 5 complete.\n",
      "Batch 73 of epoch 5 complete.\n",
      "Batch 74 of epoch 5 complete.\n",
      "Batch 75 of epoch 5 complete.\n",
      "Batch 76 of epoch 5 complete.\n",
      "Batch 77 of epoch 5 complete.\n",
      "Batch 78 of epoch 5 complete.\n",
      "Batch 79 of epoch 5 complete.\n",
      "Batch 80 of epoch 5 complete.\n",
      "Batch 81 of epoch 5 complete.\n",
      "Batch 82 of epoch 5 complete.\n",
      "Batch 83 of epoch 5 complete.\n",
      "Batch 84 of epoch 5 complete.\n",
      "Batch 85 of epoch 5 complete.\n",
      "Batch 86 of epoch 5 complete.\n",
      "Batch 87 of epoch 5 complete.\n",
      "Batch 88 of epoch 5 complete.\n",
      "Batch 89 of epoch 5 complete.\n",
      "Batch 90 of epoch 5 complete.\n",
      "Batch 91 of epoch 5 complete.\n",
      "Batch 92 of epoch 5 complete.\n",
      "Batch 93 of epoch 5 complete.\n",
      "Batch 94 of epoch 5 complete.\n",
      "Batch 95 of epoch 5 complete.\n",
      "Batch 96 of epoch 5 complete.\n",
      "Train loss: 0.02\n",
      "Dev loss: 0.14\n",
      "Dev acc: 0.96\n",
      "Dev f1: 0.90\n",
      "Dev precision: 0.95\n",
      "Dev recall: 0.85\n",
      "Epoch 6\n",
      "Batch 0 of epoch 6 complete.\n",
      "Batch 1 of epoch 6 complete.\n",
      "Batch 2 of epoch 6 complete.\n",
      "Batch 3 of epoch 6 complete.\n",
      "Batch 4 of epoch 6 complete.\n",
      "Batch 5 of epoch 6 complete.\n",
      "Batch 6 of epoch 6 complete.\n",
      "Batch 7 of epoch 6 complete.\n",
      "Batch 8 of epoch 6 complete.\n",
      "Batch 9 of epoch 6 complete.\n",
      "Batch 10 of epoch 6 complete.\n",
      "Batch 11 of epoch 6 complete.\n",
      "Batch 12 of epoch 6 complete.\n",
      "Batch 13 of epoch 6 complete.\n",
      "Batch 14 of epoch 6 complete.\n",
      "Batch 15 of epoch 6 complete.\n",
      "Batch 16 of epoch 6 complete.\n",
      "Batch 17 of epoch 6 complete.\n",
      "Batch 18 of epoch 6 complete.\n",
      "Batch 19 of epoch 6 complete.\n",
      "Batch 20 of epoch 6 complete.\n",
      "Batch 21 of epoch 6 complete.\n",
      "Batch 22 of epoch 6 complete.\n",
      "Batch 23 of epoch 6 complete.\n",
      "Batch 24 of epoch 6 complete.\n",
      "Batch 25 of epoch 6 complete.\n",
      "Batch 26 of epoch 6 complete.\n",
      "Batch 27 of epoch 6 complete.\n",
      "Batch 28 of epoch 6 complete.\n",
      "Batch 29 of epoch 6 complete.\n",
      "Batch 30 of epoch 6 complete.\n",
      "Batch 31 of epoch 6 complete.\n",
      "Batch 32 of epoch 6 complete.\n",
      "Batch 33 of epoch 6 complete.\n",
      "Batch 34 of epoch 6 complete.\n",
      "Batch 35 of epoch 6 complete.\n",
      "Batch 36 of epoch 6 complete.\n",
      "Batch 37 of epoch 6 complete.\n",
      "Batch 38 of epoch 6 complete.\n",
      "Batch 39 of epoch 6 complete.\n",
      "Batch 40 of epoch 6 complete.\n",
      "Batch 41 of epoch 6 complete.\n",
      "Batch 42 of epoch 6 complete.\n",
      "Batch 43 of epoch 6 complete.\n",
      "Batch 44 of epoch 6 complete.\n",
      "Batch 45 of epoch 6 complete.\n",
      "Batch 46 of epoch 6 complete.\n",
      "Batch 47 of epoch 6 complete.\n",
      "Batch 48 of epoch 6 complete.\n",
      "Batch 49 of epoch 6 complete.\n",
      "Batch 50 of epoch 6 complete.\n",
      "Batch 51 of epoch 6 complete.\n",
      "Batch 52 of epoch 6 complete.\n",
      "Batch 53 of epoch 6 complete.\n",
      "Batch 54 of epoch 6 complete.\n",
      "Batch 55 of epoch 6 complete.\n",
      "Batch 56 of epoch 6 complete.\n",
      "Batch 57 of epoch 6 complete.\n",
      "Batch 58 of epoch 6 complete.\n",
      "Batch 59 of epoch 6 complete.\n",
      "Batch 60 of epoch 6 complete.\n",
      "Batch 61 of epoch 6 complete.\n",
      "Batch 62 of epoch 6 complete.\n",
      "Batch 63 of epoch 6 complete.\n",
      "Batch 64 of epoch 6 complete.\n",
      "Batch 65 of epoch 6 complete.\n",
      "Batch 66 of epoch 6 complete.\n",
      "Batch 67 of epoch 6 complete.\n",
      "Batch 68 of epoch 6 complete.\n",
      "Batch 69 of epoch 6 complete.\n",
      "Batch 70 of epoch 6 complete.\n",
      "Batch 71 of epoch 6 complete.\n",
      "Batch 72 of epoch 6 complete.\n",
      "Batch 73 of epoch 6 complete.\n",
      "Batch 74 of epoch 6 complete.\n",
      "Batch 75 of epoch 6 complete.\n",
      "Batch 76 of epoch 6 complete.\n",
      "Batch 77 of epoch 6 complete.\n",
      "Batch 78 of epoch 6 complete.\n",
      "Batch 79 of epoch 6 complete.\n",
      "Batch 80 of epoch 6 complete.\n",
      "Batch 81 of epoch 6 complete.\n",
      "Batch 82 of epoch 6 complete.\n",
      "Batch 83 of epoch 6 complete.\n",
      "Batch 84 of epoch 6 complete.\n",
      "Batch 85 of epoch 6 complete.\n",
      "Batch 86 of epoch 6 complete.\n",
      "Batch 87 of epoch 6 complete.\n",
      "Batch 88 of epoch 6 complete.\n",
      "Batch 89 of epoch 6 complete.\n",
      "Batch 90 of epoch 6 complete.\n",
      "Batch 91 of epoch 6 complete.\n",
      "Batch 92 of epoch 6 complete.\n",
      "Batch 93 of epoch 6 complete.\n",
      "Batch 94 of epoch 6 complete.\n",
      "Batch 95 of epoch 6 complete.\n",
      "Batch 96 of epoch 6 complete.\n",
      "Train loss: 0.04\n",
      "Dev loss: 0.20\n",
      "Dev acc: 0.96\n",
      "Dev f1: 0.90\n",
      "Dev precision: 0.95\n",
      "Dev recall: 0.85\n",
      "Epoch 7\n",
      "Batch 0 of epoch 7 complete.\n",
      "Batch 1 of epoch 7 complete.\n",
      "Batch 2 of epoch 7 complete.\n",
      "Batch 3 of epoch 7 complete.\n",
      "Batch 4 of epoch 7 complete.\n",
      "Batch 5 of epoch 7 complete.\n",
      "Batch 6 of epoch 7 complete.\n",
      "Batch 7 of epoch 7 complete.\n",
      "Batch 8 of epoch 7 complete.\n",
      "Batch 9 of epoch 7 complete.\n",
      "Batch 10 of epoch 7 complete.\n",
      "Batch 11 of epoch 7 complete.\n",
      "Batch 12 of epoch 7 complete.\n",
      "Batch 13 of epoch 7 complete.\n",
      "Batch 14 of epoch 7 complete.\n",
      "Batch 15 of epoch 7 complete.\n",
      "Batch 16 of epoch 7 complete.\n",
      "Batch 17 of epoch 7 complete.\n",
      "Batch 18 of epoch 7 complete.\n",
      "Batch 19 of epoch 7 complete.\n",
      "Batch 20 of epoch 7 complete.\n",
      "Batch 21 of epoch 7 complete.\n",
      "Batch 22 of epoch 7 complete.\n",
      "Batch 23 of epoch 7 complete.\n",
      "Batch 24 of epoch 7 complete.\n",
      "Batch 25 of epoch 7 complete.\n",
      "Batch 26 of epoch 7 complete.\n",
      "Batch 27 of epoch 7 complete.\n",
      "Batch 28 of epoch 7 complete.\n",
      "Batch 29 of epoch 7 complete.\n",
      "Batch 30 of epoch 7 complete.\n",
      "Batch 31 of epoch 7 complete.\n",
      "Batch 32 of epoch 7 complete.\n",
      "Batch 33 of epoch 7 complete.\n",
      "Batch 34 of epoch 7 complete.\n",
      "Batch 35 of epoch 7 complete.\n",
      "Batch 36 of epoch 7 complete.\n",
      "Batch 37 of epoch 7 complete.\n",
      "Batch 38 of epoch 7 complete.\n",
      "Batch 39 of epoch 7 complete.\n",
      "Batch 40 of epoch 7 complete.\n",
      "Batch 41 of epoch 7 complete.\n",
      "Batch 42 of epoch 7 complete.\n",
      "Batch 43 of epoch 7 complete.\n",
      "Batch 44 of epoch 7 complete.\n",
      "Batch 45 of epoch 7 complete.\n",
      "Batch 46 of epoch 7 complete.\n",
      "Batch 47 of epoch 7 complete.\n",
      "Batch 48 of epoch 7 complete.\n",
      "Batch 49 of epoch 7 complete.\n",
      "Batch 50 of epoch 7 complete.\n",
      "Batch 51 of epoch 7 complete.\n",
      "Batch 52 of epoch 7 complete.\n",
      "Batch 53 of epoch 7 complete.\n",
      "Batch 54 of epoch 7 complete.\n",
      "Batch 55 of epoch 7 complete.\n",
      "Batch 56 of epoch 7 complete.\n",
      "Batch 57 of epoch 7 complete.\n",
      "Batch 58 of epoch 7 complete.\n",
      "Batch 59 of epoch 7 complete.\n",
      "Batch 60 of epoch 7 complete.\n",
      "Batch 61 of epoch 7 complete.\n",
      "Batch 62 of epoch 7 complete.\n",
      "Batch 63 of epoch 7 complete.\n",
      "Batch 64 of epoch 7 complete.\n",
      "Batch 65 of epoch 7 complete.\n",
      "Batch 66 of epoch 7 complete.\n",
      "Batch 67 of epoch 7 complete.\n",
      "Batch 68 of epoch 7 complete.\n",
      "Batch 69 of epoch 7 complete.\n",
      "Batch 70 of epoch 7 complete.\n",
      "Batch 71 of epoch 7 complete.\n",
      "Batch 72 of epoch 7 complete.\n",
      "Batch 73 of epoch 7 complete.\n",
      "Batch 74 of epoch 7 complete.\n",
      "Batch 75 of epoch 7 complete.\n",
      "Batch 76 of epoch 7 complete.\n",
      "Batch 77 of epoch 7 complete.\n",
      "Batch 78 of epoch 7 complete.\n",
      "Batch 79 of epoch 7 complete.\n",
      "Batch 80 of epoch 7 complete.\n",
      "Batch 81 of epoch 7 complete.\n",
      "Batch 82 of epoch 7 complete.\n",
      "Batch 83 of epoch 7 complete.\n",
      "Batch 84 of epoch 7 complete.\n",
      "Batch 85 of epoch 7 complete.\n",
      "Batch 86 of epoch 7 complete.\n",
      "Batch 87 of epoch 7 complete.\n",
      "Batch 88 of epoch 7 complete.\n",
      "Batch 89 of epoch 7 complete.\n",
      "Batch 90 of epoch 7 complete.\n",
      "Batch 91 of epoch 7 complete.\n",
      "Batch 92 of epoch 7 complete.\n",
      "Batch 93 of epoch 7 complete.\n",
      "Batch 94 of epoch 7 complete.\n",
      "Batch 95 of epoch 7 complete.\n",
      "Batch 96 of epoch 7 complete.\n",
      "Train loss: 0.02\n",
      "Dev loss: 0.17\n",
      "Dev acc: 0.97\n",
      "Dev f1: 0.92\n",
      "Dev precision: 0.93\n",
      "Dev recall: 0.91\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_dataloader, dev_dataloader, epochs, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7366,
     "status": "ok",
     "timestamp": 1651930239483,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "IMLJcPkaO4jF",
    "outputId": "6bc96af6-191c-4934-a2a5-085d254a3ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9662288930581614\n",
      "F1: 0.9203539823008849\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "dev_probs = predict(model, dev_dataloader, gpu)\n",
    "dev_predictions = covert_to_label(dev_probs)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(dev_data['label'], dev_predictions)))\n",
    "print(\"F1: \" + str(f1_score(dev_data['label'], dev_predictions)))\n",
    "print(\"Precision: \"+ str(precision_score(dev_data['label'], dev_predictions)))\n",
    "print(\"Recall: \" + str(recall_score(dev_data['label'], dev_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1651930239483,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "AkeaFXuDjlKn"
   },
   "outputs": [],
   "source": [
    "def predict_for_test(model, dataloader, gpu):\n",
    "  model.eval()\n",
    "  res = []\n",
    "  with torch.no_grad():\n",
    "    for input_ids, attention_masks in dataloader:\n",
    "      cuda_input_ids = input_ids.cuda(gpu)\n",
    "      cuda_attention_masks = attention_masks.cuda(gpu)\n",
    "      logits = model(cuda_input_ids, cuda_attention_masks)\n",
    "      probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "      probs = probs.detach().cpu().numpy()\n",
    "      for prob in probs:\n",
    "        res.append(prob)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8037,
     "status": "ok",
     "timestamp": 1651930247505,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "T5UE9YXrjvB3",
    "outputId": "e9b45ce5-b485-4eb0-cab8-b2d3f66c8b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "558\n"
     ]
    }
   ],
   "source": [
    "test_probs = predict_for_test(model, test_dataloader, gpu)\n",
    "test_predictions = covert_to_label(test_probs)\n",
    "print(test_predictions)\n",
    "print(len(test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1651930525323,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "EVt43YSqj-A9"
   },
   "outputs": [],
   "source": [
    "index = range(len(test_predictions))\n",
    "res_map = {\"Id\":index, \"Predicted\":test_predictions}\n",
    "df = DataFrame(res_map)\n",
    "df.to_csv('/content/drive/MyDrive/nlp/bertweet_v4_res.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPiyiFt6BvtpIve56HVEOTa",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1L-sATDSaGhm4WzYExR8DYE06tH92GTLo",
   "name": "BERTweet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1007951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pandas.core.frame import DataFrame\n",
    "import re\n",
    "import tensorflow_text as text\n",
    "import emoji\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import EarlyStopping\n",
    "from transformers import AutoTokenizer\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364da7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_Data():\n",
    "    train_ids = open(\"data/train.data.txt\", \"r\")\n",
    "    train_labels = open(\"data/train.label.txt\", \"r\")\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    for train_ids_str, label in zip(train_ids.readlines(), train_labels.readlines()):\n",
    "        train_ids_list = train_ids_str.strip().split(\",\")\n",
    "        temp_json_list = []\n",
    "        if not os.path.exists(\"data/train_object/\" + train_ids_list[0] + \".json\"):\n",
    "            continue\n",
    "        for train_id in train_ids_list:\n",
    "            train_path = \"data/train_object/\" + train_id + \".json\"\n",
    "            if os.path.exists(train_path):\n",
    "                temp_json_list.append(json.load(open(train_path, \"r\")))\n",
    "        # sort according to time\n",
    "        temp_json_list = sorted(temp_json_list, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], \"%a %b %d %H:%M:%S +0000 %Y\")))\n",
    "        train_data.append(temp_json_list)\n",
    "        train_label.append(0 if label.strip() == \"nonrumour\" else 1)\n",
    "        temp_map = {\"data\": train_data, \"label\": train_label}\n",
    "    return DataFrame(temp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117a5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_Data():\n",
    "    dev_ids = open(\"data/dev.data.txt\", \"r\")\n",
    "    dev_labels = open(\"data/dev.label.txt\", \"r\")\n",
    "    dev_data = []\n",
    "    dev_label = []\n",
    "    for dev_ids_str, label in zip(dev_ids.readlines(), dev_labels.readlines()):\n",
    "        dev_ids_list = dev_ids_str.strip().split(\",\")\n",
    "        temp_json_list = []\n",
    "        if not os.path.exists(\"data/dev_object/\" + dev_ids_list[0] + \".json\"):\n",
    "            continue\n",
    "        for dev_id in dev_ids_list:\n",
    "            dev_path = \"data/dev_object/\" + dev_id + \".json\"\n",
    "            if os.path.exists(dev_path):\n",
    "                temp_json_list.append(json.load(open(dev_path, \"r\")))\n",
    "        # sort according to time\n",
    "        temp_json_list = sorted(temp_json_list, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], \"%a %b %d %H:%M:%S +0000 %Y\")))\n",
    "        dev_data.append(temp_json_list)\n",
    "        dev_label.append(0 if label.strip() == \"nonrumour\" else 1)\n",
    "        temp_map = {\"data\": dev_data, \"label\": dev_label}\n",
    "    return DataFrame(temp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c1a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_Data():\n",
    "    test_ids = open(\"data/test.data.txt\", \"r\")\n",
    "    test_data = []\n",
    "    for test_ids_str in test_ids.readlines():\n",
    "        test_ids_list = test_ids_str.strip().split(\",\")\n",
    "        temp_json_list = []\n",
    "        if not os.path.exists(\"data/tweet-objects/\" + test_ids_list[0] + \".json\"):\n",
    "            continue\n",
    "        for test_id in test_ids_list:\n",
    "            test_path = \"data/tweet-objects/\" + test_id + \".json\"\n",
    "            if os.path.exists(test_path):\n",
    "                temp_json_list.append(json.load(open(test_path, \"r\")))\n",
    "        # sort according to time\n",
    "        temp_json_list = sorted(temp_json_list, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], \"%a %b %d %H:%M:%S +0000 %Y\")))\n",
    "        test_data.append(temp_json_list)\n",
    "        temp_map = {\"data\": test_data}\n",
    "    return DataFrame(temp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f648582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covid_Data():\n",
    "    test_ids = open(\"data/covid.data.txt\", \"r\")\n",
    "    test_data = []\n",
    "    for test_ids_str in test_ids.readlines():\n",
    "        test_ids_list = test_ids_str.strip().split(\",\")\n",
    "        temp_json_list = []\n",
    "        if not os.path.exists(\"data/covid_object/\" + test_ids_list[0] + \".json\"):\n",
    "            continue\n",
    "        for test_id in test_ids_list:\n",
    "            test_path = \"data/covid_object/\" + test_id + \".json\"\n",
    "            if os.path.exists(test_path):\n",
    "                temp_json_list.append(json.load(open(test_path, \"r\")))\n",
    "        # sort according to time\n",
    "        temp_json_list = sorted(temp_json_list, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], \"%a %b %d %H:%M:%S +0000 %Y\")))\n",
    "        test_data.append(temp_json_list)\n",
    "        temp_map = {\"data\": test_data}\n",
    "    return DataFrame(temp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c4a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba731bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16c49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinText(data):\n",
    "    input_text = []\n",
    "    labels = []\n",
    "    for x in range(len(data[\"data\"])):\n",
    "        x_text = []\n",
    "        for y in range(len(data[\"data\"][x])):\n",
    "            x_text.append(preprocess(data[\"data\"][x][y][\"text\"]))\n",
    "        input_text.append(tokenizer.sep_token.join(x_text))\n",
    "        labels.append(data[\"label\"][x])\n",
    "        temp_map = {\"text\": input_text, \"label\": labels}\n",
    "    return DataFrame(temp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6500b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_test_text(data):\n",
    "    input_text = []\n",
    "    for x in range(len(data[\"data\"])):\n",
    "        x_text = []\n",
    "        for y in range(len(data[\"data\"][x])):\n",
    "            x_text.append(preprocess(data[\"data\"][x][y][\"text\"]))\n",
    "        input_text.append(tokenizer.sep_token.join(x_text))\n",
    "        temp_map = {\"text\": input_text}\n",
    "    return DataFrame(temp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06cdbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        if t.startswith('@') and len(t) > 1:\n",
    "            t = \"@user\"\n",
    "        if t.startswith(\"http\"):\n",
    "            t = \"http\"\n",
    "#         t = emoji.replace_emoji(t, replace=\"\")\n",
    "        t = re.sub(emoji.get_emoji_regexp(), r\"\", t)\n",
    "        t = t.lower()\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367036ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-5e928568997a>:9: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  t = re.sub(emoji.get_emoji_regexp(), r\"\", t)\n"
     ]
    }
   ],
   "source": [
    "train_data = get_train_Data()\n",
    "train_data = joinText(train_data)\n",
    "train_text = train_data[\"text\"].values.tolist()\n",
    "train_label = train_data[\"label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f18b48e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-5e928568997a>:9: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  t = re.sub(emoji.get_emoji_regexp(), r\"\", t)\n"
     ]
    }
   ],
   "source": [
    "dev_data = get_dev_Data()\n",
    "dev_data = joinText(dev_data)\n",
    "dev_text = dev_data[\"text\"].values.tolist()\n",
    "dev_label = dev_data[\"label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b052eea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-5e928568997a>:9: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  t = re.sub(emoji.get_emoji_regexp(), r\"\", t)\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_Data()\n",
    "test_data = join_test_text(test_data)\n",
    "test_text = test_data[\"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c64f6339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-5e928568997a>:9: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  t = re.sub(emoji.get_emoji_regexp(), r\"\", t)\n"
     ]
    }
   ],
   "source": [
    "covid_data = get_covid_Data()\n",
    "covid_data = join_test_text(covid_data)\n",
    "covid_text = covid_data[\"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2dc0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62760835 2.4591195 ]\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(train_data['label']), y = train_data['label'])\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b90fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
    "preprocessed_text = preprocessor(text_input)\n",
    "outputs = encoder(preprocessed_text)\n",
    "\n",
    "l = tf.keras.layers.Dropout(0.6, name=\"dropout\")(outputs[\"pooled_output\"])\n",
    "l = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(outputs[\"pooled_output\"])\n",
    "\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bea07067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer[0][0]',            \n",
      "                                None, 768),                       'keras_layer[0][1]',            \n",
      "                                 'default': (None,                'keras_layer[0][2]']            \n",
      "                                768),                                                             \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 109,483,009\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a9e90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "#     tfa.metrics.F1Score(name=\"F1\",num_classes=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2afb4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "049bd755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 871s 1s/step - loss: 0.3721 - accuracy: 0.8223 - precision: 0.6220 - recall: 0.3208 - val_loss: 0.2252 - val_accuracy: 0.9123 - val_precision: 0.8469 - val_recall: 0.7217\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 842s 1s/step - loss: 0.1504 - accuracy: 0.9399 - precision: 0.8636 - recall: 0.8365 - val_loss: 0.1527 - val_accuracy: 0.9347 - val_precision: 0.8333 - val_recall: 0.8696\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 850s 1s/step - loss: 0.0511 - accuracy: 0.9834 - precision: 0.9620 - recall: 0.9560 - val_loss: 0.1534 - val_accuracy: 0.9534 - val_precision: 0.9167 - val_recall: 0.8609\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 848s 1s/step - loss: 0.0127 - accuracy: 0.9955 - precision: 0.9905 - recall: 0.9874 - val_loss: 0.1483 - val_accuracy: 0.9478 - val_precision: 0.9223 - val_recall: 0.8261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d4b0c5ac0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_text, train_label, batch_size=2, epochs=4, \n",
    "          validation_data=(dev_text, dev_label),\n",
    "          callbacks = EarlyStopping(monitor='val_loss', patience=3, verbose=2),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "550403ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 49s 3s/step - loss: 0.1483 - accuracy: 0.9478 - precision: 0.9223 - recall: 0.8261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14833712577819824,\n",
       " 0.9477611780166626,\n",
       " 0.9223300814628601,\n",
       " 0.8260869383811951]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_text, dev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d534d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = model.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e010f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = np.where(test_label > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b4cccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = []\n",
    "for i in range(len(test_predicted)):\n",
    "    test_prediction.append(test_predicted[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10a686e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(len(test_prediction))\n",
    "res_map = {\"Id\":index, \"Predicted\":test_prediction}\n",
    "df = DataFrame(res_map)\n",
    "df.to_csv(\"bert_predict12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92b2496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_label = model.predict(covid_text)\n",
    "covid_predicted = np.where(covid_label > 0.5, 1, 0)\n",
    "covid_prediction = []\n",
    "for i in range(len(covid_prediction)):\n",
    "    covid_prediction.append(covid_predicted[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eeaee76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(len(covid_prediction))\n",
    "res_map = {\"Id\":index, \"Predicted\":covid_prediction}\n",
    "df = DataFrame(res_map)\n",
    "df.to_csv(\"covid_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e09d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
